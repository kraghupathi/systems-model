#+TITLE:     The Cluster Model
#+DATE:      2015-03-25 Wed
#+PROPERTY: session *scratch*
#+PROPERTY: results output
#+PROPERTY: exports code
#+SETUPFILE: org-templates/level-0.org
#+OPTIONS: ^nil

* Introduction
  This document describes in detail the model of the systems cluster
  at VLEAD.  The tools, systems, configurations, setup files and
  related discussions are all part of the model.
 
* Prerequisites
  This section enlists the basic knowledge the reader must have to be
  able to comprehend the details of this model. The reader must be
  familiar with the following:
  + Networking basics
  + Ansible 
  + Amazon Web Service (AWS) [EC2, VM creation, console, AMI etc.]
  + OpenVZ 
  + Version control basics
To know further about these please refer [[Appendix][Appendix]].

* The Cluster Model
  The cluster model describes the set of systems which together
  provide the infrastructure for the hosting of the virtual-labs.
  This infrastructure is setup at the following different locations:
  + [[Base4 Cluster][Base4]]
  + [[Base1 Cluster][Base1]]
  + [[Amazon Web Services (AWS) Cluster][AWS]]
  The names of the cluster are given based on the locations in which
  they are deployed. Base1 and Base4 are Centos machines running
  OpenVZ kernel and are physically located in IIIT. 

* Purpose of multiple clusters
** Base4 Cluster
   This cluster is a development cluster.  This cluster is used to
   test new changes made to the develop branch before they are
   considered as stable and merged with the master branch.

** Base1 Cluster 
   Stable commits to the master branch on the base4 cluster are
   released.  Each release has a tag and a version number.  A new
   release is tested on base1 cluster to re-verify its soundness on
   the staging environment, before it is pushed to the production
   environment on AWS.

** Amazon Web Services (AWS) Cluster
   This cluster is the production cluster.  This cluster is modified
   only after changes have been verified on both development (base4)
   and staging (base1) clusters.

   /It should be noted that ADS adapter used on base1 and base4 is/
   /different than adapter used on AWS.  Hence some problems may arise/
   /due to use of different adapter in production in comparison to/
   /staging and development./

   This is the main cluster used by the external virtual-labs users
   across the nation.  

* Bootstrapping of a cluster
  An independent operating system such as a container or a VM or even
  a physical machine is referred as a node.  The collection of such
  related and connected nodes forms a cluster.  Each node in the
  cluster has a specific purpose that it serves.  To setup an entire
  cluster initially, each of the component nodes are setup
  individually in a planned and specific manner.  This process of
  setup of individual nodes in a specific manner to setup a new
  cluster is called the bootstrapping process.  This process is
  tightly related to the provisioning method used on the corresponding
  cluster.
** Provisioning 
  Following provisioning methods have been used on the individual
  clusters:
  - AWS cluster :: AWS cluster is created using VMs as nodes.  These
                   VMs are provisioned using AWS web console, AWS CLI
                   tools or AWS python API
  - Base1 cluster :: Base1 cluster is created using OpenVZ containers
                     which use bridged networking with ethernet
                     interfaces (=--netif_add=).  These containers do
                     not use venet interfaces (=--ipadd=) as venet
                     interfaces do not allow routing to be changed.
                     In base1 cluster we need nodes to have
                     configurable routing so that we can set a custom
                     gateway.  
  - Base4 cluster :: Same as base1

** Bootstrapping the cluster
   [[./bootstrapping.org]]
* Design of the cluster model
  The diagram below depicts the architecture of the nodes in the
  cluster model.  This architecture is same for all the three
  deployments (base1, base4 and AWS).  The diagram shows the
  network-setup of the cluster and connectivity between a few key
  nodes.

   #+CAPTION:  Cluster Network Diagram
   #+LABEL:  fig-cluster-network-diagram
   [[./diagrams/overall-cluster-network-diagram.png]]
   
  In this diagram IP1 and IP2 refer to the only two public IP's being
  used by the system.  IP1 is the public IP assigned to router and IP2
  is the public IP assigned to ansible.  Normal virtual-lab users only
  see and contact router.  VLEAD team uses ansible to manage the
  cluster.  In near future ADS interface will also be accessible via
  router, for all virtual-labs developers, perhaps through a different
  port. \\
  This diagram focuses on depicting the important connections in the
  network. There are several other connections which are not shown.
  For example, ansible is connected to every node in the cluster.  All
  the connections are not shown in the diagram. Also there are some
  nodes which are not shown, for example the rsnapshot server, rsyslog
  server, ossec server are not shown. But these nodes are configured
  and are being used in the cluster but are not shown to keep the
  diagram simple.
   
  /In near future an ADS interface will also be accessible via/
  /router, for all the virtual-labs developers, perhaps through a/
  /different port./

* Nodes in the cluster
  There are several nodes in the cluster which are all common to the
  various clusters. The list of nodes is as below:
  
  - [[./rsyslog-server.org][Rsyslog server]]
  - [[./private-dns.org][Private DNS]]
  - [[./public-dns.org][Public DNS]]
  - [[./rp-awstats.org][Reverse Proxy]]
  - [[./nagios-server.org][Nagios server]]
  - [[./router.org][Router]]
  - [[./rsnapshot-server.org][Backup server]]
  - [[./ossec-server.org][OSSEC server]] 
  - [[./lab_rsnapshot_server.org][Lab Backup Server]]
  - [[./lab-role.org][Lab node]]

  After the bootstrapping process the nodes in the cluster can be
  brought up using the script below. It is an ansible script which
  will bring up all the nodes one after another with the required
  roles.

#+BEGIN_SRC YAML :tangle configure_servers.yaml 
---
#Complete site configuration file
#One yaml file for each server is included here
#Server yaml file matches server FQDN


- include: rsnapshot_server.yaml

#- include: ossec_server.yaml

- include: config_server.yaml

- include: router.yaml

- include: public_dns.yaml

- include: private_dns.yaml

- include: rsyslog_server.yaml

- include: reverseproxy_server.yaml

- include: nagios_server.yaml

- include: ads_server.yaml

#- include: lab_rsnapshot_server.yaml

#+END_SRC 
#+BEGIN_SRC YAML :tangle install_clients_in_servers.yaml 
---
#Complete site configuration file
#One yaml file for each server is included here
#Server yaml file matches server FQDN


- include: install_clients_in_rsnapshot_server.yaml

#- include: install_clients_in_ossec_server.yaml

- include: install_clients_in_config_server.yaml

- include: install_clients_in_router_server.yaml

- include: install_clients_in_public_dns.yaml

- include: install_clients_in_private_dns.yaml

- include: install_clients_in_rsyslog_server.yaml

- include: install_clients_in_reverseproxy_server.yaml

- include: install_clients_in_nagios_server.yaml

#- include: ads_server.yaml

#- include: lab_rsnapshot_server.yaml

#+END_SRC 
* AWS compliance
  AWS provides a list of security best practices which should be
  followed. These practices help the AWS client take safety
  precautions based on the various features Amazon provides. Using
  these a compliance test of the AWS cluster was done. The following
  file describes the same.

  [[./vlead-compliance-with-aws-security-best-practicses.org][Vlead compliance with aws security best practicses]]

* Known Issues
  - A separate repository for systems related issues which includes
    the cluster and its implementation can be viewed [[https://bitbucket.org/vlead/systems/issues?status%3Dnew&status%3Dopen][here]].
* Appendix
** Version control
   The cluster model would involve timely changes, be it in the
   configuration of the nodes or the architecture of the
   cluster. Version control provides a mechanism which would keep
   track of all such changes. Along with tracking changes, it also
   provides the facility to revert back to a previous state of the
   system. The version control system used in this model is "git". To
   know more about git [[https://git-scm.com/][click here]].

** OpenVZ
   OpenVZ is a simple open source kernel level virtualization.  It is
   used to create several isolated containers (Virtual Environments)
   on the same physical resources. Details on why OpenVZ is used can
   be found [[https://openvz.org/Use_cases][here]]. 

   Base1 and Base4 clusters are built using such containers. To know
   more about how to setup containers etc. [[https://openvz.org/User_Guide/Operations_on_Containers][click here]].

** AWS
   AWS stands for Amazon Web Services. It is a proprietary cloud
   service provider. Maintenance and allocation of resources are taken
   care of by the service provider (Amazon). 

   AWS cluster is setup using the Amazon web services. To know more
   about AWS service please read the following :
   + [[https://en.wikipedia.org/wiki/Amazon_Web_Services][Amazon Web services]]
   + [[http://aws.amazon.com/free/][AWS Free Tier]]
   + [[http://aws.amazon.com/ec2/][Amazon EC2]]
   + [[https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html][AWS EC2 user guide]]
     
** Networking
   Some basics topics in networking that are required to know are:
   + Bridged networks (using OpenVZ) [[[https://en.wikipedia.org/wiki/Bridging_%2528networking%2529][ Bridging]], [[https://openvz.org/Virtual_Ethernet_device][Bridging in OpenVZ]], [[https://openvz.org/Category:Networking][OpenVZ Networking]] ]
   + Concept of subnets [ [[https://en.wikipedia.org/wiki/Subnetwork][Subnetwork]] ] 
   + Basic knowledge of IP addressing [ [[https://en.wikipedia.org/wiki/IP_address][IP addresing]] ]

** Ansible
   Ansible is a configuration management tool which is used for
   configuring the cluster. It provides remote configuration of nodes
   over SSH. For more details view the following [[https://en.wikipedia.org/wiki/Ansible_%2528software%2529][Ansible]] , [[http://docs.ansible.com/][Ansible
   Documentation]].
* COMMENT Bootstrapping of a cluster deployment
  The cluster is a collection of several nodes.  Each of these nodes
  have a specific purpose that they serve.  To setup the entire
  cluster for the first time we need to setup each of the nodes
  individually.  This process is called the bootstrapping process.
  This process is tightly related to provisioning on corresponding
  cluster. 
** Provisioning vs bootstrapping
   *Provisioning* is a term used to describe the process for bringing up
   a system for setting up the node.\\
   *Bootstrapping* process uses this system to setup the
   nodes. Provisioning is a part of the bootstrapping process, hence
   they cannot be separated.\\
** Bootstrapping of Cluster
   All the nodes of the three deployments are same.  The main
   difference is in the provisioning.  The details of provisioning of
   these clusters is described in the following sections.

*** Provisioning for Base1 and Base4
    The 
# comment Above statement is incomplete
*** Provisioning for AWS
# comment This section needs to be filled    
* COMMENT Difference in the base1 and AWS cluster
  Most of the components of base1 and base4 clusters are same as AWS
  cluster.  The main difference is in the provisioning.  The details of
  provisioning of these clusters is described in this section.

** Provisioning of the base1 and base4 clusters
   *TODO*
** Provisioning of the AWS cluster
   *TODO*
